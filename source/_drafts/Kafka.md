---
title: 消息队列
tags: [Kafka,MQ]
date: 2021-03-23 14:43
---

## Structure

- MQ 作用?
    - 解耦/异步/削峰 结合业务
- MQ 高可用:kafka 一个 topic 分多个 partition, 每个 partition 都会有副本 replica 在多个 broker 上.天然分布式保证高可用.
- MQ 如何保证消费幂等性?
    - 业务下游上去处理.比如,在冷库里加唯一约束;查询数据日志是否有被消费;在redis 中添加记录.
- MQ 如何保证可靠性传输?消息不丢失.
    - 消费端数据丢失: 还没消费到消费者这儿宕机了, 但kafka收到提交的 offset.解决:关闭自动提交,完成消费后再手动提交.这儿引申出的问题是消费完成后未提交而宕机,解决方案是在消费业务中保证幂等.
    - 生产端数据丢失: 生产完数据后宕机,需要 设置 acks=all,设置每条数据写入所有的 replica 才认为是成功, retries=max 失败的话无限重试
    - kafka 数据丢失: Broker 宕机,重选 leader 时,未同步到 follower 上的数据丢失.解决:设置 replication.factor 大于1,以保证 partition 有至少两个副本;再 min.insync.replicas 大于1,至少有一个 follower 与 leader 保持联系.结合上面生产者数据丢失的配置
- 保证消息顺序
    - 生产数据时指定key,让同一类数据都到同一个 partition 中且保持顺序.在消费者那儿让单线程进行消费,吞吐量低.如果必须多线程消费数据,可以让有前后关系的数据绑定在一个有顺序的组合消息,消费者消费组合的消息.或者维护队列让不同的线程在不同的队列中找消息消费.
- 如何设计一个 MQ?
    - 高伸缩性,高吞吐量: 分布式每个 partition 放一个机器,存一部分数据,资源不够时可以直接加机器
    - 高可用: leader 所在 broker 宕机重选一 leader
    - 数据可靠性: 
- 如何设计一个高并发系统？
    - 系统拆分 将并发业务分到不同机器与库里
    - MQ 削峰,高并发写的场景让其在排除慢慢处理
    - redis 缓存,高并发读的场景
    - elasticsearch, 联表查询场景
    - 逃离不了的高并发写库 分库分表,读写分离 

## Redis

- 内存淘汰策略
    - 定期删除 每隔 100 ms 随机抽取 key 检查删除
    - 隋性删除 到过期时间后查询返回 nil 同时删除此 key
    - 内存淘汰机制
        - noeviction 不淘汰
        - allkey-random 所有键在内存不够时候随机淘汰
        - allkey-lru 内存不够时使用最近最少使用淘汰
        - volatile-random 内存不足时,随机淘汰设置过过期时间的key
        - volatile-lru 内存不足时,淘汰最近最少使用的key
        - volatile-ttl 内存不足时,淘汰ttl最先过期的key

### 基于 token

- 基于 token 解决多实例用户 session 数据

### 读写分离

- 原理:从库在将主库 binlog copy 到自己的 relayLog 中,再执行copy 过来的日志;
- 两种机制:
    - semi-sync 半同步复制,每次新的写入在从库中执行后再响应ack给主库,主库收到 ack 才确认此次同步成功,解决主库不可用的异常.
    - 并行复制,库级别并行
- 同步延迟解决方案:
    - 最粗暴方法:让关键读也走主库,此方案会违背主从分离的主旨
    - 业务代码注意到从库的延迟
    - 打开并行复制
    - 主库拆分为多个

### 项目

- 整个项目是一个基于新能源充电桩的系统.整个系统给c端用户提供充电服务,或者对接一些第三方的平台或用户以提供互联互通的服务.整个充电流程是用户在APP端发起充电后,我们系统接收到用户请求会对用户做些验证,验证之后再通过我们的flock平台对充电桩发起一些指令.桩这边收到指令做出的响应数据也会先到flock平台,我们再将flock清洗过的数据响应给用户.这里面用到kafka做了些异步解耦, 还用redis做了些热数据的缓存以减轻数据库压力.后期数据增加后用sharding-jdbc做了读写分离.我主要负责了移动端的充电流程/消息推送相关的开发.
- 难点:整个系统进行过一次性能优化,针对高频访问接口做过压力测试.这边发现一些查询系统电枪状态的接口会出现瓶颈.当qps达到700 800 的时候,后台数据库的机器cpu就跑满了,app端接口响应也延迟很久.这边原因就在于在地图首页的接口并不需要用户登录就可以查看市内所有充电场站状态,而平均一个场站的电枪数量近100个,一次查询会查询好几百个电枪的数据.为了优化这个点了,将场站电枪这些基础查询数据缓存到redis中,每次查询时先走缓存,如果查询不到再走到mysql,经过这样优化后,大量请求都在前期缓存就处理了.
    - 
