---
title: 消息队列
tags: [Kafka,MQ]
date: 2021-03-23 14:43
---

## [Kafka](https://kafka.apache.org/documentation/#majordesignelements)

- 利用线性读写将数据直接在 pagecache 中操作在磁盘上,而不是常规在内存中读写在内存不够使用时再flush到磁盘上,实现快速的读写性能与更大的容量更便宜的持久化成本.

### 常量时间复杂度

消息系统使用的持久化数据结构通常为每个消费者队列使用一个相关的 BTree 或者其他常用的随机访问数据结构来维护消息的元数据.BTree 有更多的变体结构并能够在消息系统中支持各种事务与非事务主义.

### 消费者

- 一个消息要发送给多个消费者进行消费,需要设置不同消费者在不同的 group 里,否则只会被其中一个消费者所消费.

## Structure

- MQ 作用?
    - 解耦/异步/削峰 结合业务
- MQ 高可用:kafka 一个 topic 分多个 partition, 每个 partition 都会有副本 replica 在多个 broker 上.天然分布式保证高可用.
- MQ 如何保证消费幂等性?
    - 业务下游上去处理.比如,在冷库里加唯一约束;查询数据日志是否有被消费;在redis 中添加记录.
- MQ 如何保证可靠性传输?消息不丢失.
    - 消费端数据丢失: 还没消费到消费者这儿宕机了, 但kafka收到提交的 offset.解决:关闭自动提交,完成消费后再手动提交.这儿引申出的问题是消费完成后未提交而宕机,解决方案是在消费业务中保证幂等.
    - 生产端数据丢失: 生产完数据后宕机,需要 设置 acks=all,设置每条数据写入所有的 replica 才认为是成功, retries=max 失败的话无限重试
    - kafka 数据丢失: Broker 宕机,重选 leader 时,未同步到 follower 上的数据丢失.解决:设置 replication.factor 大于1,以保证 partition 有至少两个副本;再 min.insync.replicas 大于1,至少有一个 follower 与 leader 保持联系.结合上面生产者数据丢失的配置
- 保证消息顺序
    - 生产数据时指定key,让同一类数据都到同一个 partition 中且保持顺序.在消费者那儿让单线程进行消费,吞吐量低.如果必须多线程消费数据,可以让有前后关系的数据绑定在一个有顺序的组合消息,消费者消费组合的消息.或者维护队列让不同的线程在不同的队列中找消息消费.
- 如何设计一个 MQ?
    - 高伸缩性,高吞吐量: 分布式每个 partition 放一个机器,存一部分数据,资源不够时可以直接加机器
    - 高可用: leader 所在 broker 宕机重选一 leader
    - 数据可靠性: 
- 如何设计一个高并发系统？
    - 系统拆分 将并发业务分到不同机器与库里
    - MQ 削峰,高并发写的场景让其在排除慢慢处理
    - redis 缓存,高并发读的场景
    - elasticsearch, 联表查询场景
    - 逃离不了的高并发写库 分库分表,读写分离

## Redis

- 内存淘汰策略
    - 定期删除 每隔 100 ms 随机抽取 key 检查删除
    - 隋性删除 到过期时间后查询返回 nil 同时删除此 key
    - 内存淘汰机制
        - noeviction 不淘汰
        - allkey-random 所有键在内存不够时候随机淘汰
        - allkey-lru 内存不够时使用最近最少使用淘汰
        - volatile-random 内存不足时,随机淘汰设置过过期时间的key
        - volatile-lru 内存不足时,淘汰最近最少使用的key
        - volatile-ttl 内存不足时,淘汰ttl最先过期的key

### 基于 token

- 基于 token 解决多实例用户 session 数据

### 读写分离

- 原理:从库在将主库 binlog copy 到自己的 relayLog 中,再执行copy 过来的日志;
- 两种机制:
    - semi-sync 半同步复制,每次新的写入在从库中执行后再响应ack给主库,主库收到 ack 才确认此次同步成功,解决主库不可用的异常.
    - 并行复制,库级别并行
- 同步延迟解决方案:
    - 最粗暴方法:让关键读也走主库,此方案会违背主从分离的主旨
    - 业务代码注意到从库的延迟
    - 打开并行复制
    - 主库拆分为多个

## zookeeper

- zookeeper 作用
    - 分布协调,系统A发起一个消息到MQ但同时关心这个消息的消费结果,就可以在 zookeeper 中注册一个节点值监听器,当B消费后就更新这个节点值,这时A就知道消费结果.
    - 分布式锁,当需要限制多个实例对同一个数据进行修改时,就在 zookeeper 上创建一个 znode 作为锁,当其他实例也来修改时去获取此锁而不得,只能等之前的实例执行完后才能自己执行.
    - 元数据/配置信息管理,分布式系统配置信息管理,kafka/storm,dubbo 注册中心
    - HA 高可用.主进程挂了时,可以通过感知 zookeeper 切换到从进程.
- 分布式锁
    - 使用 redis 创建,如果是使用主从架构的话,只需要将请求 set key value nx px 设置一个过期时间即可,执行完了删除锁的值,为了防止任务执行过长导致锁自动过期,而删除了后来的任务执行者创建的锁,可以将 value 设置为一个 random 值,执行完成后删除这个 random 值的key.问题在于,如果发生master 宕机,主备切换.就会产生原锁数据不在,而新的任务执行过来直接在新的master机上获取锁.解决办法是:redis 使用 cluster 集群,master 分片.这种架构下创建一个锁需要让大部分的master 机子上创建成功才算创建成功.如果少部分 master 机子发生主备切换依然不影响锁的创建.如果创建失败就把原先创建的锁给删除.
    - 使用 zookeeper 创建 znode 作为锁.后来的竞争者发现 znode 创建了就只能监听此锁.当前面的执行者执行完成后,删除 znode 释放锁也通知客户端.后面等待的客户端就可以重新加锁.
    - zk 锁模型更简单,不需要不停地尝试获取少了性能上的开销,出现建锁的任务执行异常挂了时,znode 也会自动删除释放锁.

### 项目

- 我叫康珊,从17年开始做java后端开发.刚开始在一家互联网出行公司做后端开发,后来18年就到神马专车这边做一个新能源的项目,这个项目
- 整个项目是一个基于新能源充电桩的系统.整个系统给c端用户提供充电服务,或者对接一些第三方的平台或用户以提供互联互通的服务.整个充电流程是用户在APP端发起充电后,我们系统接收到用户请求会对用户做些验证,验证之后再通过我们的flock平台对充电桩发起一些指令.桩这边收到指令做出的响应数据也会先到flock平台,我们再将flock清洗过的数据响应给用户.这里面用到kafka做了些异步解耦, 还用redis做了些热数据的缓存以减轻数据库压力.后期数据增加后用sharding-jdbc做了读写分离.我主要负责了移动端的充电流程/消息推送相关的开发,还有一些管理后台和企业端的接口开发.
- 难点:整个系统进行过一次性能优化,针对高频访问接口做过压力测试.这边发现一些查询系统电枪状态的接口会出现瓶颈.当qps达到700 800 的时候,后台数据库的机器cpu就跑满了,app端接口响应也延迟很久.这边原因就在于在地图首页的接口并不需要用户登录就可以查看市内所有充电场站状态,而平均一个场站的电枪数量近100个,一次查询会查询好几百个电枪的数据.为了优化这个点了,将场站电枪这些基础查询数据缓存到redis中,每次查询时先走缓存,如果查询不到再走到mysql,经过这样优化后,大量请求都在前期缓存就处理了.
    - 这样优化后,redis 单机就可以抗过万的请求,冷库没什么压力.但目前这样实现有个问题是双写不一致的风险缓存雪崩的风险. 一主多从可以实现主备切换,实现一定的高可用.也可以让读请求分散在多个从实例上.如果业务进一步扩展,出现高频写的需求时候,可以用 redis cluster 集群方式,将数据进行分片存储在多个 master 实例上,每个master配备多个slave 实现高可用.使用这种数据分片的集群方式,会带来分布式寻址问题.因为不同的key会被分配在不同的master实例上,将写的压力分散在多个机器上.最简单的分布式寻址方式直接使用hash,当新的节点增加或有节点宕机被移除时,需要对所有的key数据进行重新hash.成本很高.为解决这个问题需要引入一致性hash算法.它的做法是将所有的节点连成环状,每个key数据hash后落在环上顺着一个方向找下一个节点.这样做可以实现增加一个节点或减少一个节点,只需要对其中一个节点的数据进行重新hash或者将宕机节点的数据落到后一个节点上去.这种解决方案在异常情况出现时切要某一个节点数据陡量增减,打破平均分配.解决这个问题可以在原来hash slot 环基础上将每个节点平均分成多份均匀地分布在这个环上,这样节点宕机或新增节点重新hash时时候可以将重新hash的数据均匀分摊到多个节点上.
    - redis hash slot(自带的).redis 本身有 18376 个node.所有node 均分在各个master 节点上.每个key进行 hash sha 算法后与 18376 取模运算,将其放在各个node上.当有节点增减,只需要将节点上的node分摊到其他节点或其他节点分摊node 到新节点上.key层面不关心

## Mybatis

### placeholder

#{} 与 ${} 区别

- #{} 会产生预编译.而${}只会直接替换,一般用于表名或列名[ref](https://mybatis.org/mybatis-3/sqlmap-xml.html)
- #{} 因为预编译而在第一次执行时会编译好,可以防止sql注入,也因此更快.
